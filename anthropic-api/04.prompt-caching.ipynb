{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fc22d1-7748-4e5d-af2f-9e479eeca375",
   "metadata": {},
   "source": [
    "# 03: Prompt Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101083e8-914b-41ec-9fb9-114457163a66",
   "metadata": {},
   "source": [
    "[docs](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd447e0-7481-44c0-988f-b11453c89e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785fafa-d48f-4c39-9c6e-b030f6dcbaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.environ[\"ANTHROPIC_API_KEY\"]:\n",
    "    print(\"environment variable ANTHROPIC_API_KEY not found, checking in api.txt\")\n",
    "    with open(\"api.txt\") as i:\n",
    "        api = i.read().strip()\n",
    "        if not api:\n",
    "            print(\"nothing found in api.txt, create a key in console.anthropic.com and paste it there\")\n",
    "        else:\n",
    "            os.environ[\"ANTHROPIC_API_KEY\"] = api\n",
    "            print(\"key found in api.txt\")  \n",
    "else:\n",
    "    print(\"environment variable ANTHROPIC_API_KEY found\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017f014-858d-4049-8d82-8caab0483159",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Anthropic()\n",
    "MODEL_NAME=\"claude-3-5-sonnet-20241022\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e9c16-181b-4919-a130-4dc3edaaa785",
   "metadata": {},
   "source": [
    "### Loading The Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30510915-fa70-4440-996d-cd8db6acb313",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/frankenstein.txt', 'r') as file:\n",
    "    book_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f30f0d7-81f7-4113-b340-ae95b53aa774",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(book_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfc6ab-673c-4a5f-9b91-f3f931aa454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book_content[1000:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366b1ec-23ad-4d04-9c9d-7246a296e854",
   "metadata": {},
   "source": [
    "## Uncached Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44035f9-2faa-44d5-90c4-3faf41917fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def make_non_cached_api_call():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What happens in chapter 3?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=500,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    return response, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283894bf-1806-4f75-b49b-73afbbfdcd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cached_response, non_cached_time = make_non_cached_api_call()\n",
    "print(f\"Non-cached time: {non_cached_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nOutput (non-cached):\")\n",
    "print(non_cached_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede4c3d-317b-4267-b912-f1dbc68e85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_cached_response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75249390-271a-45b9-8e4b-abbfeae9e8e8",
   "metadata": {},
   "source": [
    "## Cached Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319b0d7-e35e-4cc5-9510-cb48d89be8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cached_api_call():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"<book>\" + book_content + \"</book>\",\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What happens in chapter 5?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=500,\n",
    "        messages=messages,\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    return response, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a0dce-4020-450f-beec-420d1255f2ea",
   "metadata": {},
   "source": [
    "Note: this is likely to exceed the tokens-per-minute limit we are allowed to have... :}, need to wait for a bit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce4d45-80a4-4f03-af59-3942b717ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response1, duration1 = make_cached_api_call()\n",
    "print(\"response 1\")\n",
    "print(f\"duration: {duration1}\")\n",
    "print(response1.usage)  # `cache_creation_input_tokens` should have all the tokens!\n",
    "print()\n",
    "\n",
    "print(response1.content[0].text)\n",
    "\n",
    "time.sleep(60) # wait 1 minute to prevent block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d487e-bde7-4a63-9b44-ad6cd42dbf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response2, duration2 = make_cached_api_call()\n",
    "\n",
    "print(f\"response 2\")\n",
    "print(f\"duration: {duration2}\")\n",
    "print(response2.usage) # `cache_read_input_tokens` should have all the tokens!\n",
    "print()\n",
    "\n",
    "print(response2.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f7791-befc-4e5b-ba5d-dd0fa0d3d657",
   "metadata": {},
   "source": [
    "## Prompt Caching Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae9d10-addf-4e40-8140-bb4e9aa10358",
   "metadata": {},
   "source": [
    "* Cache write tokens are 25% more expensive than base input tokens\n",
    "* Cache read tokens are 90% cheaper than base input tokens\n",
    "* Regular input and output tokens are priced at standard rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01838c83-b41b-4f8c-b30f-bca5249d319c",
   "metadata": {},
   "source": [
    "## Multi-Turn Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07040e-46e3-488b-8194-4d0375fcba2c",
   "metadata": {},
   "source": [
    "When implementing a chatbot, adding `\"cache_control\": {\"type\": \"ephemeral\"}` to the **last two messages** will have the following effect:\n",
    "1. The first (earlier) call to the cache will attempt to retrieve any available cache up until that point. If no cache is found, one will be created.\n",
    "2. The second (later) call will update any existing cache, so that in the next round, the first (earlier) call to cache will retrieve pre-computed information up until that point (the whole conversation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df6742-2784-41b4-bd82-ed31f52d6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    # ...long conversation so far\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Hello, can you tell me more about the solar system\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Certainly! The solar system is the collection of celestial bodies that orbit our Sun. It consists of eight planets, numerous moons, asteroids, comets, and other objects. The planets, in order from closest to farthest from the Sun, are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Each planet has its own unique characteristics and features. Is there a specific aspect of the solar system you'd like to know more about?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Tell me more about Mars.\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19b119-6753-4a91-8ca6-5012993bd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    # ...long conversation so far\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Hello, can you tell me more about the solar system\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Certainly! The solar system is the collection of celestial bodies that orbit our Sun. It consists of eight planets, numerous moons, asteroids, comets, and other objects. The planets, in order from closest to farthest from the Sun, are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. Each planet has its own unique characteristics and features. Is there a specific aspect of the solar system you'd like to know more about?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Tell me more about Mars.\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'd love to tell you about Mars.  Mars is....\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"That's really neat.  Tell me about Pluto!\",\n",
    "                \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff033710-f2f6-4fb0-a1db-745e3d52be2d",
   "metadata": {},
   "source": [
    "## Chatbot with caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234dfa95-15b8-4ef9-a443-5e411952b639",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "print(\"Simple Chatbot (type 'quit' to exit)\")\n",
    "# Store conversation history\n",
    "messages = []\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \")\n",
    "    # Check for quit command\n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    # Add user message to history, with cache\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_input,\n",
    "                    \"cache_control\": {\"type\": \"ephemeral\"}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "   \n",
    "    # caching: removing cache from older messages (keep cache only for\n",
    "    # last 2 exchanges/4 messages) (improved code with Claude)\n",
    "    if len(messages) > 4:\n",
    "        # Find the oldest message that should have its cache removed\n",
    "        old_message_index = len(messages) - 5\n",
    "        if old_message_index >= 0 and \"content\" in messages[old_message_index]:\n",
    "            # If it's a user message with content as a list\n",
    "            if isinstance(messages[old_message_index][\"content\"], list):\n",
    "                for content_item in messages[old_message_index][\"content\"]:\n",
    "                    if \"cache_control\" in content_item:\n",
    "                        del content_item[\"cache_control\"]\n",
    "                        \n",
    "    # for debugging\n",
    "    # print(*messages, sep=\"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Get response from Claude\n",
    "        response = client.messages.create(\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=200,\n",
    "            messages=messages\n",
    "        )\n",
    "        # Extract and print Claude's response\n",
    "        asst_message = response.content[0].text\n",
    "        print(\"Assistant:\", asst_message)\n",
    "        \n",
    "        # Add assistant response to history\n",
    "        messages.append({\"role\": \"assistant\", \"content\": asst_message})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print()\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622550a6-59a0-492b-8047-91fcc9aa520b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
