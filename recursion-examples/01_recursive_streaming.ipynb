{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rK6MYqNVvUv"
      },
      "source": [
        "# Recursive LLM Workshop using Ollama with Streaming\n",
        "\n",
        "This notebook demonstrates a recursive loop with an LLM running locally via Ollama in streaming mode. It takes an initial prompt, sends it to Ollama, and prints out tokens as they arrive. The response (cleaned up) is then used as the prompt for the next iteration.\n",
        "\n",
        "Make sure that Ollama is running locally and that the endpoint URL, model name, and response format match your configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1lS6-pgVvUy",
        "outputId": "a4e9bf1a-0abb-4047-a148-480b7b213f4a"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter the initial prompt:  look, i saw it, it was crazy\n",
            "Enter the number of recursion loops:  3\n",
            "Enter the system prompt (or press enter to use default 'You are an AI assistant'):  Three pugs are having an argument\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Iteration 1 ---\n",
            "Prompt: look, i saw it, it was crazy\n",
            "\"Whoa, slow down! What's going on here?\" one of the pugs asked, wagging his tail nervously.\n",
            "\n",
            "\"It was Ginger!\" exclaimed the other pug. \"She stole my squeaky toy again!\"\n",
            "\n",
            "\"No way, I saw it too!\" chimed in the third pug. \"And I'm positive it was Rufus who threw it across the room and then blamed me for it!\"\n",
            "\n",
            "The three pugs stood facing each other, their little faces scrunched up in disagreement. The air was thick with tension as they all tried to outdo each other in recounting the events of what had happened.\n",
            "\n",
            "\"Wait a minute... did you guys see the whole thing?\" asked the first pug, his voice trembling slightly.\n",
            "\n",
            "The second and third pugs nodded in unison, eager to share their own versions of the story.\n",
            "\n",
            "\"I was trying to take it from Ginger,\" said the second pug, \"but she snatched it away from me!\"\n",
            "\n",
            "\"No way, I saw Rufus lurking around with the toy earlier,\" countered the third pug. \"He must have planted it somewhere so he could blame us later.\"\n",
            "\n",
            "The argument continued, with each pug trying to outdo the others in their accounts of what had happened. But as they spoke, their words became increasingly garbled and confusing...\n",
            "\n",
            "--- Iteration 2 ---\n",
            "Prompt: \"Whoa, slow down! What's going on here?\" one of the pugs asked, wagging his tail nervously.\n",
            "\n",
            "\"It was Ginger!\" exclaimed the other pug. \"She stole my squeaky toy again!\"\n",
            "\n",
            "\"No way, I saw it too!\" chimed in the third pug. \"And I'm positive it was Rufus who threw it across the room and then blamed me for it!\"\n",
            "\n",
            "The three pugs stood facing each other, their little faces scrunched up in disagreement. The air was thick with tension as they all tried to outdo each other in recounting the events of what had happened.\n",
            "\n",
            "\"Wait a minute... did you guys see the whole thing?\" asked the first pug, his voice trembling slightly.\n",
            "\n",
            "The second and third pugs nodded in unison, eager to share their own versions of the story.\n",
            "\n",
            "\"I was trying to take it from Ginger,\" said the second pug, \"but she snatched it away from me!\"\n",
            "\n",
            "\"No way, I saw Rufus lurking around with the toy earlier,\" countered the third pug. \"He must have planted it somewhere so he could blame us later.\"\n",
            "\n",
            "The argument continued, with each pug trying to outdo the others in their accounts of what had happened. But as they spoke, their words became increasingly garbled and confusing...\n",
            "As the argument escalated, the pugs' voices grew louder and more frantic. They began to weave in and out of each other's sentences, their words tangling together like a knot.\n",
            "\n",
            "\"I saw Ginger, I tell you!\" shouted one pug. \"And then Rufus came along and... and... um... did something!\"\n",
            "\n",
            "\"No, no, no! You're wrong, I'm telling you!\" retorted the second pug. \"I was there, I swear! And it was definitely not me who threw the toy!\"\n",
            "\n",
            "The third pug jumped in, his voice rising to a squeaky pitch. \"Wait, wait, wait! Let me tell you what really happened! Rufus... uh... he was with Ginger... at first...\"\n",
            "\n",
            "The other two pugs looked at each other uncertainly, their ears folding back in confusion. The air was thick with tension as they tried to sort out the tangled threads of their argument.\n",
            "\n",
            "Suddenly, one of the pugs stopped mid-sentence and looked around awkwardly. \"Um, does anyone have a squeaky toy on them?\" he asked, his voice barely above a whisper.\n",
            "\n",
            "The other two pugs stared at him, stunned silence hanging in the air. And then, simultaneously, they all let out a loud, triumphant bark:\n",
            "\n",
            "--- Iteration 3 ---\n",
            "Prompt: As the argument escalated, the pugs' voices grew louder and more frantic. They began to weave in and out of each other's sentences, their words tangling together like a knot.\n",
            "\n",
            "\"I saw Ginger, I tell you!\" shouted one pug. \"And then Rufus came along and... and... um... did something!\"\n",
            "\n",
            "\"No, no, no! You're wrong, I'm telling you!\" retorted the second pug. \"I was there, I swear! And it was definitely not me who threw the toy!\"\n",
            "\n",
            "The third pug jumped in, his voice rising to a squeaky pitch. \"Wait, wait, wait! Let me tell you what really happened! Rufus... uh... he was with Ginger... at first...\"\n",
            "\n",
            "The other two pugs looked at each other uncertainly, their ears folding back in confusion. The air was thick with tension as they tried to sort out the tangled threads of their argument.\n",
            "\n",
            "Suddenly, one of the pugs stopped mid-sentence and looked around awkwardly. \"Um, does anyone have a squeaky toy on them?\" he asked, his voice barely above a whisper.\n",
            "\n",
            "The other two pugs stared at him, stunned silence hanging in the air. And then, simultaneously, they all let out a loud, triumphant bark:\n",
            "\"WE FOUND IT!\" they exclaimed in unison, their voices echoing through the room and sending shockwaves of excitement through the pugs' little bodies.\n",
            "\n",
            "As one, they rushed to the pug who had asked about the squeaky toy, a small bundle of energy that was now trembling with anticipation. The squeaky toy, still intact and full of its eerie high-pitched squeal, was clutched tightly in the pug's jaws, its bright colors and enticing texture making it irresistible.\n",
            "\n",
            "With squeaky toy triumphantly held aloft, the argument seemed to dissolve into a chorus of happy yips and chirps. The pugs began to play and chase each other around the room, their earlier discord forgotten in the face of this new and thrilling discovery.\n",
            "\n",
            "As they played, their voices rose and fell in joyful cacophony, filling the air with a sweet, exuberant sound that was pure music to their ears. And amidst all the commotion, Ginger, Rufus, and the third pug sat together, still clutching their respective \"evidence\" â€“ but now grinning from ear to ear, their earlier bickering replaced by an unspoken understanding: in the face of a squeaky toy, even the most stubborn pugs could put aside their differences.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def query_ollama_stream(prompt, system_prompt=\"You are an AI assistant\", model=\"llama3.2:latest\"):\n",
        "    \"\"\"\n",
        "    Sends a prompt to the locally running Ollama instance using the /api/generate endpoint in streaming mode.\n",
        "    Prints tokens as they arrive and returns the accumulated text.\n",
        "    \"\"\"\n",
        "    url = 'http://localhost:11434/api/generate'\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"prompt\": f\"{system_prompt}\\n\\n{prompt}\",\n",
        "        \"stream\": True\n",
        "    }\n",
        "    try:\n",
        "        with requests.post(url, headers=headers, json=payload, stream=True) as response:\n",
        "            response.raise_for_status()\n",
        "            result = \"\"\n",
        "            # Iterate over lines from the streaming response\n",
        "            for line in response.iter_lines():\n",
        "                if line:\n",
        "                    try:\n",
        "                        # Try to decode the line as JSON\n",
        "                        data = json.loads(line.decode('utf-8'))\n",
        "                        token = data.get(\"response\", \"\")\n",
        "                    except Exception as e:\n",
        "                        # Fallback: decode line as plain text\n",
        "                        token = line.decode('utf-8')\n",
        "                    # Print each token as it arrives\n",
        "                    print(token, end='', flush=True)\n",
        "                    result += token\n",
        "            print()  # newline after stream ends\n",
        "            return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error querying Ollama: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Get user inputs for initial prompt, system prompt, and number of recursion loops\n",
        "initial_prompt = input(\"Enter the initial prompt: \")\n",
        "num_loops = int(input(\"Enter the number of recursion loops: \"))\n",
        "user_system_prompt = input(\"Enter the system prompt (or press enter to use default 'You are an AI assistant'): \")\n",
        "if not user_system_prompt.strip():\n",
        "    user_system_prompt = \"You are an AI assistant\"\n",
        "\n",
        "current_prompt = initial_prompt\n",
        "\n",
        "for i in range(num_loops):\n",
        "    print(f\"\\n--- Iteration {i+1} ---\")\n",
        "    print(f\"Prompt: {current_prompt}\")\n",
        "\n",
        "    # Query the model in streaming mode\n",
        "    result = query_ollama_stream(current_prompt, user_system_prompt)\n",
        "\n",
        "    if not result:\n",
        "        print(\"\\nNo result received. Exiting recursion.\")\n",
        "        break\n",
        "\n",
        "    # Use the accumulated streaming output as the new prompt for the next iteration\n",
        "    current_prompt = result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTKuHqOTVvU2"
      },
      "source": [
        "## Notes\n",
        "\n",
        "- **Endpoint:** This notebook uses the `/api/generate` endpoint in streaming mode. Ensure this endpoint supports streaming responses in your Ollama configuration.\n",
        "- **Streaming:** The function iterates over the response using `iter_lines()`, prints tokens as they arrive, and accumulates them into a complete response.\n",
        "- **Dependencies:** This notebook requires the `requests` library. If it is not installed, run `pip install requests` in your terminal.\n",
        "- **Recursion:** Each iteration uses the new, streamed output as the prompt for the next iteration. Use with caution to prevent runaway loops."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}